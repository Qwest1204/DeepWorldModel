{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-21T10:20:23.786266Z",
     "start_time": "2025-12-21T10:20:23.776366Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as f\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from models.vae_dataset import VAENpDataset\n",
    "from models.vae import ResVAE\n",
    "from torch import optim\n",
    "from models.actor import ActorCritic, BackboneNetwork\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:20:25.837560Z",
     "start_time": "2025-12-21T10:20:24.000825Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = VAENpDataset(path_to_np_files=\"data\", img_size=96)",
   "id": "4bb4b3beb6448ab8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 14.04it/s]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:20:25.850928Z",
     "start_time": "2025-12-21T10:20:25.844635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_checkpoint(model, optimizer, path, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    loss = checkpoint['loss']\n",
    "    print(f'Checkpoint loaded: {path}, resuming from epoch {start_epoch}')\n",
    "    return start_epoch, loss"
   ],
   "id": "6a6a65624c9c84bf",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:20:25.903959Z",
     "start_time": "2025-12-21T10:20:25.854603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resvae = ResVAE(3, hidden_dim=4096, z_dim=32)\n",
    "optimizer = optim.Adam(resvae.parameters(), lr=0.00001)"
   ],
   "id": "1d6bc7b8342fc32b",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:20:26.119237Z",
     "start_time": "2025-12-21T10:20:25.912575Z"
    }
   },
   "cell_type": "code",
   "source": "_, _ = load_checkpoint(resvae, optimizer, './checkpoints/checkpoint_epoch_20.pt', \"cpu\")",
   "id": "14bf36da5ea83dfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded: ./checkpoints/checkpoint_epoch_20.pt, resuming from epoch 20\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:20:26.663856Z",
     "start_time": "2025-12-21T10:20:26.657882Z"
    }
   },
   "cell_type": "code",
   "source": "x = dataset[0]",
   "id": "e39d1738e40b1c6f",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:26:59.527278Z",
     "start_time": "2025-12-21T10:26:59.521658Z"
    }
   },
   "cell_type": "code",
   "source": "x.shape",
   "id": "b280aceee1089c19",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96, 96])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:21:02.622742Z",
     "start_time": "2025-12-21T10:21:02.617671Z"
    }
   },
   "cell_type": "code",
   "source": "z, _, _ = resvae.encode(x.unsqueeze(0))",
   "id": "2674ac777f58bcbe",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T10:21:05.951858Z",
     "start_time": "2025-12-21T10:21:05.948929Z"
    }
   },
   "cell_type": "code",
   "source": "z.shape",
   "id": "7fa43cd437ca4aa0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:07:04.865573Z",
     "start_time": "2025-12-20T21:07:04.527399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from PIL import Image"
   ],
   "id": "ad7130bbe17bbc74",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:07:04.874138Z",
     "start_time": "2025-12-20T21:07:04.869608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_vae_animation(npz_path, vae_model, save_path=\"vae_reconstruction.gif\", num_frames=400):\n",
    "    \"\"\"\n",
    "    npz_path: путь к файлу с данными (предполагаем ключ 'obs')\n",
    "    vae_model: ваша загруженная модель (torch.nn.Module)\n",
    "    save_path: куда сохранить гифку\n",
    "    num_frames: сколько кадров анимировать\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Загрузка данных\n",
    "    print(f\"Загрузка данных из {npz_path}...\")\n",
    "    data = np.load(npz_path)\n",
    "\n",
    "    # Предполагаем, что картинки лежат по ключу 'obs' или 'observations'\n",
    "    # Если у вас другой ключ, поменяйте его здесь\n",
    "    key = 'obs' if 'obs' in data else list(data.keys())[0]\n",
    "    observations = data[key] # Ожидаем форму (N, 96, 96, 3) или (N, 64, 64, 3)\n",
    "\n",
    "    # 2. Подготовка модели\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    vae_model.to(device)\n",
    "    vae_model.eval() # Переключаем в режим оценки (выключает dropout и т.д.)\n",
    "\n",
    "    # 3. Настройка графика\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off') # Убираем оси координат\n",
    "\n",
    "    # Инициализация пустой картинки\n",
    "    # Берем первый кадр просто чтобы узнать размер\n",
    "    img_plot = ax.imshow(observations[0])\n",
    "\n",
    "    print(\"Генерация анимации...\")\n",
    "\n",
    "    def update(frame_idx):\n",
    "        # --- ПРЕПРОЦЕССИНГ ---\n",
    "        # Берем кадр из датасета. Он сейчас (H, W, C) и 0-255 uint8\n",
    "        raw_frame = observations[frame_idx]\n",
    "\n",
    "        # Конвертируем в формат PyTorch: (1, C, H, W) и нормализуем 0-1\n",
    "        # permute(2, 0, 1) делает из HWC -> CHW\n",
    "        input_tensor = torch.from_numpy(raw_frame).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "        # Добавляем Batch dimension -> (1, C, H, W)\n",
    "        x = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        # --- ВАШ КОД + ИНФЕРЕНС ---\n",
    "        with torch.no_grad(): # Отключаем градиенты для скорости\n",
    "            # ВАШ СНИППЕТ ВСТАВЛЕН СЮДА\n",
    "            # x подается в VAE, на выходе реконструированная картинка\n",
    "\n",
    "            # Примечание: Ваш сниппет возвращает PIL Image.\n",
    "            # Matplotlib хочет numpy array. Поэтому оборачиваем в np.array()\n",
    "            reconstructed_pil = Image.fromarray(\n",
    "                (resvae(x)[0].squeeze(0).cpu().detach().numpy().transpose(1,2,0).astype(np.float32)*255).astype(np.uint8)\n",
    "            )\n",
    "\n",
    "            reconstructed_img = np.array(reconstructed_pil)\n",
    "\n",
    "        # Обновляем картинку на графике\n",
    "        img_plot.set_data(reconstructed_img)\n",
    "        ax.set_title(f\"Frame: {frame_idx}\")\n",
    "        return [img_plot]\n",
    "\n",
    "    # Создание анимации\n",
    "    # frames=num_frames ограничивает длину, чтобы не рендерить весь датасет часами\n",
    "    ani = FuncAnimation(fig, update, frames=range(num_frames), blit=True)\n",
    "\n",
    "    # Сохранение\n",
    "    print(f\"Сохранение в {save_path}...\")\n",
    "    ani.save(save_path, fps=20, writer='pillow') # 'pillow' сохраняет gif\n",
    "    print(\"Готово!\")\n",
    "    plt.close()"
   ],
   "id": "d58f294ad8a83b51",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:07:19.695497Z",
     "start_time": "2025-12-20T21:07:07.097149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_npz = \"data/car_racing_data_ep_12.npz\" # Или \"data_1.npz\"\n",
    "\n",
    "# 2. Здесь должна быть инициализация вашей модели\n",
    "\n",
    "# ПРОВЕРКА: Если модели нет под рукой, код упадет.\n",
    "    # Раскомментируйте строку ниже для запуска функции, если vae уже определен в вашем коде\n",
    "create_vae_animation(path_to_npz, resvae)"
   ],
   "id": "1db247afd8f70d50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных из data/car_racing_data_ep_12.npz...\n",
      "Генерация анимации...\n",
      "Сохранение в vae_reconstruction.gif...\n",
      "Готово!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:48:15.850968Z",
     "start_time": "2025-12-20T21:48:15.843901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_returns(rewards, discount_factor):\n",
    "    returns = []\n",
    "    cumulative_reward = 0\n",
    "    for r in reversed(rewards):\n",
    "        cumulative_reward = r + cumulative_reward * discount_factor\n",
    "        returns.insert(0, cumulative_reward)\n",
    "    returns = torch.tensor(returns)\n",
    "    # normalize the return\n",
    "    returns = (returns - returns.mean()) / returns.std()\n",
    "    return returns"
   ],
   "id": "8e048ea321af66a6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:48:28.391742Z",
     "start_time": "2025-12-20T21:48:28.389559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_advantages(returns, values):\n",
    "    advantages = returns - values\n",
    "    # Normalize the advantage\n",
    "    advantages = (advantages - advantages.mean()) / advantages.std()\n",
    "    return advantages"
   ],
   "id": "9119958ca1419612",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:48:42.874198Z",
     "start_time": "2025-12-20T21:48:42.870045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_surrogate_loss(\n",
    "        actions_log_probability_old,\n",
    "        actions_log_probability_new,\n",
    "        epsilon,\n",
    "        advantages):\n",
    "    advantages = advantages.detach()\n",
    "    policy_ratio = (\n",
    "            actions_log_probability_new - actions_log_probability_old\n",
    "            ).exp()\n",
    "    surrogate_loss_1 = policy_ratio * advantages\n",
    "    surrogate_loss_2 = torch.clamp(\n",
    "            policy_ratio, min=1.0-epsilon, max=1.0+epsilon\n",
    "            ) * advantages\n",
    "    surrogate_loss = torch.min(surrogate_loss_1, surrogate_loss_2)\n",
    "    return surrogate_loss"
   ],
   "id": "6cc561c32ec64496",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:49:15.227301Z",
     "start_time": "2025-12-20T21:49:15.223728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_losses(\n",
    "        surrogate_loss, entropy, entropy_coefficient, returns, value_pred):\n",
    "    entropy_bonus = entropy_coefficient * entropy\n",
    "    policy_loss = -(surrogate_loss + entropy_bonus).sum()\n",
    "    value_loss = f.smooth_l1_loss(returns, value_pred).sum()\n",
    "    return policy_loss, value_loss"
   ],
   "id": "991b8fab89594299",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:49:54.448763Z",
     "start_time": "2025-12-20T21:49:53.519923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "import numpy as np"
   ],
   "id": "785ed575013dcf38",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniilogorodnikov/PycharmProjects/DeepWorld/.venv/lib/python3.13/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:49:59.676218Z",
     "start_time": "2025-12-20T21:49:59.527249Z"
    }
   },
   "cell_type": "code",
   "source": "env = gym.make(\"CarRacing-v3\", render_mode=\"human\")",
   "id": "f443dd9fa6b8f5d2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:50:11.241139Z",
     "start_time": "2025-12-20T21:50:11.238015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_agent(hidden_dimensions, dropout):\n",
    "    INPUT_FEATURES = env.observation_space.shape[0]\n",
    "    HIDDEN_DIMENSIONS = hidden_dimensions\n",
    "    ACTOR_OUTPUT_FEATURES = env.action_space.n\n",
    "    CRITIC_OUTPUT_FEATURES = 1\n",
    "    DROPOUT = dropout\n",
    "    actor = BackboneNetwork(\n",
    "            INPUT_FEATURES, HIDDEN_DIMENSIONS, ACTOR_OUTPUT_FEATURES, DROPOUT)\n",
    "    critic = BackboneNetwork(\n",
    "            INPUT_FEATURES, HIDDEN_DIMENSIONS, CRITIC_OUTPUT_FEATURES, DROPOUT)\n",
    "    agent = ActorCritic(actor, critic)\n",
    "    return agent"
   ],
   "id": "79d6be4a8a263746",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T21:50:21.671693Z",
     "start_time": "2025-12-20T21:50:21.668858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_training():\n",
    "    states = []\n",
    "    actions = []\n",
    "    actions_log_probability = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    return states, actions, actions_log_probability, values, rewards, done, episode_reward"
   ],
   "id": "1708510614e7417a",
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
